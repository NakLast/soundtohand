{"ast":null,"code":"var _jsxFileName = \"D:\\\\Sorn\\\\Project(NSC)\\\\Code\\\\project-nsc\\\\soundtohand\\\\src\\\\component\\\\VoiceRec.js\",\n    _s = $RefreshSig$();\n\nimport React, { useState, useEffect, Fragment } from 'react';\nimport MicIcon from '@material-ui/icons/Mic';\nimport FiberManualRecordIcon from '@material-ui/icons/FiberManualRecord';\nimport { Button } from '@material-ui/core';\nimport '../App.css';\nimport axios from 'axios';\nimport { DefaultPlayer as Video } from 'react-html5video';\nimport 'react-html5video/dist/styles.css';\nimport { red } from '@material-ui/core/colors';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst SpeechRecognition = mic.lang = 'th-Th';\nwindow.SpeechRecognition || window.webkitSpeechRecognition;\nconst mic = new SpeechRecognition();\nmic.continuous = true;\nmic.interimResults = true;\n\nfunction VoiceRec() {\n  _s();\n\n  const [isListening, setIsListening] = useState(false);\n  const [note, setNote] = useState(null); // const [savedNotes, setSavedNotes] = useState([])\n\n  const [cutWordTH, setCutWordTH] = useState([]);\n  var wordList = {};\n  useEffect(() => {\n    handleListen();\n  }, [isListening]);\n\n  const handleListen = () => {\n    if (isListening) {\n      mic.start();\n      mic.stop();\n\n      mic.onend = () => {\n        console.log('continue..');\n        mic.start();\n      };\n    } else {\n      mic.onend = () => {\n        console.log('Stopped Mic on Click');\n      };\n    }\n\n    mic.onstart = () => {\n      console.log('Mics on');\n    };\n\n    mic.onresult = event => {\n      const transcript = Array.from(event.results).map(result => result[0]).map(result => result.transcript).join('');\n      console.log(transcript);\n      setNote(transcript);\n      let config = {\n        'Apikey': 'rBOeYWQF1L4QEfhffQB7ubqYAJqYSWvQ'\n      }; //return axios.get(`${apiBaseURL}/v1/cryptocurrency/map`, { headers: config })\n\n      axios.get(\"https://api.aiforthai.in.th/tlexplus?text=\" + transcript, {\n        headers: config\n      }).then(response => {\n        wordList = response.data.tokens;\n        console.log(wordList);\n        setCutWordTH(wordList);\n      }).catch(error => {// alert(error)\n      });\n\n      mic.onerror = event => {\n        console.log(event.error);\n      };\n    };\n  };\n\n  return (\n    /*#__PURE__*/\n    // const handleSaveNote = () => {\n    //   setSavedNotes([...savedNotes, note])\n    //   setNote('')\n    // }\n    _jsxDEV(Fragment, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 85,\n      columnNumber: 7\n    }, this)\n  );\n}\n\n_s(VoiceRec, \"QyS7jNG0f+pPf2MNWiy5IMelje0=\");\n\n_c = VoiceRec;\nexport default VoiceRec;\n\nvar _c;\n\n$RefreshReg$(_c, \"VoiceRec\");","map":{"version":3,"sources":["D:/Sorn/Project(NSC)/Code/project-nsc/soundtohand/src/component/VoiceRec.js"],"names":["React","useState","useEffect","Fragment","MicIcon","FiberManualRecordIcon","Button","axios","DefaultPlayer","Video","red","SpeechRecognition","mic","lang","window","webkitSpeechRecognition","continuous","interimResults","VoiceRec","isListening","setIsListening","note","setNote","cutWordTH","setCutWordTH","wordList","handleListen","start","stop","onend","console","log","onstart","onresult","event","transcript","Array","from","results","map","result","join","config","get","headers","then","response","data","tokens","catch","error","onerror"],"mappings":";;;AAAA,OAAOA,KAAP,IAAgBC,QAAhB,EAA0BC,SAA1B,EAAqCC,QAArC,QAAqD,OAArD;AACA,OAAOC,OAAP,MAAoB,wBAApB;AACA,OAAOC,qBAAP,MAAkC,sCAAlC;AACA,SAASC,MAAT,QAAuB,mBAAvB;AAEA,OAAO,YAAP;AAEA,OAAOC,KAAP,MAAkB,OAAlB;AACA,SAASC,aAAa,IAAIC,KAA1B,QAAuC,kBAAvC;AACA,OAAO,kCAAP;AACA,SAASC,GAAT,QAAoB,0BAApB;;AAEA,MAAMC,iBAAiB,GACvBC,GAAG,CAACC,IAAJ,GAAW,OADX;AAEEC,MAAM,CAACH,iBAAP,IAA4BG,MAAM,CAACC,uBAAnC;AACF,MAAMH,GAAG,GAAG,IAAID,iBAAJ,EAAZ;AAEAC,GAAG,CAACI,UAAJ,GAAiB,IAAjB;AACAJ,GAAG,CAACK,cAAJ,GAAqB,IAArB;;AAEA,SAASC,QAAT,GAAoB;AAAA;;AAClB,QAAM,CAACC,WAAD,EAAcC,cAAd,IAAgCnB,QAAQ,CAAC,KAAD,CAA9C;AACA,QAAM,CAACoB,IAAD,EAAOC,OAAP,IAAkBrB,QAAQ,CAAC,IAAD,CAAhC,CAFkB,CAGlB;;AACA,QAAM,CAACsB,SAAD,EAAYC,YAAZ,IAA4BvB,QAAQ,CAAC,EAAD,CAA1C;AAGA,MAAIwB,QAAQ,GAAG,EAAf;AAEAvB,EAAAA,SAAS,CAAC,MAAM;AACdwB,IAAAA,YAAY;AACb,GAFQ,EAEN,CAACP,WAAD,CAFM,CAAT;;AAIA,QAAMO,YAAY,GAAG,MAAM;AACzB,QAAIP,WAAJ,EAAiB;AACfP,MAAAA,GAAG,CAACe,KAAJ;AACAf,MAAAA,GAAG,CAACgB,IAAJ;;AACAhB,MAAAA,GAAG,CAACiB,KAAJ,GAAY,MAAM;AAChBC,QAAAA,OAAO,CAACC,GAAR,CAAY,YAAZ;AACAnB,QAAAA,GAAG,CAACe,KAAJ;AACD,OAHD;AAID,KAPD,MAOO;AACLf,MAAAA,GAAG,CAACiB,KAAJ,GAAY,MAAM;AAChBC,QAAAA,OAAO,CAACC,GAAR,CAAY,sBAAZ;AACD,OAFD;AAGD;;AACDnB,IAAAA,GAAG,CAACoB,OAAJ,GAAc,MAAM;AAClBF,MAAAA,OAAO,CAACC,GAAR,CAAY,SAAZ;AACD,KAFD;;AAIAnB,IAAAA,GAAG,CAACqB,QAAJ,GAAeC,KAAK,IAAI;AACtB,YAAMC,UAAU,GAAGC,KAAK,CAACC,IAAN,CAAWH,KAAK,CAACI,OAAjB,EAChBC,GADgB,CACZC,MAAM,IAAIA,MAAM,CAAC,CAAD,CADJ,EAEhBD,GAFgB,CAEZC,MAAM,IAAIA,MAAM,CAACL,UAFL,EAGhBM,IAHgB,CAGX,EAHW,CAAnB;AAIAX,MAAAA,OAAO,CAACC,GAAR,CAAYI,UAAZ;AACAb,MAAAA,OAAO,CAACa,UAAD,CAAP;AAEA,UAAIO,MAAM,GAAG;AAAE,kBAAU;AAAZ,OAAb,CARsB,CAStB;;AAEAnC,MAAAA,KAAK,CAACoC,GAAN,CAAU,+CAA+CR,UAAzD,EAAqE;AAAES,QAAAA,OAAO,EAAEF;AAAX,OAArE,EAA0FG,IAA1F,CAAgGC,QAAD,IAAc;AAC3GrB,QAAAA,QAAQ,GAAGqB,QAAQ,CAACC,IAAT,CAAcC,MAAzB;AACAlB,QAAAA,OAAO,CAACC,GAAR,CAAYN,QAAZ;AAEAD,QAAAA,YAAY,CAACC,QAAD,CAAZ;AAED,OAND,EAOEwB,KAPF,CAOSC,KAAD,IAAW,CACjB;AACD,OATD;;AAWAtC,MAAAA,GAAG,CAACuC,OAAJ,GAAcjB,KAAK,IAAI;AACrBJ,QAAAA,OAAO,CAACC,GAAR,CAAYG,KAAK,CAACgB,KAAlB;AACD,OAFD;AAGD,KAzBD;AA0BD,GA3CD;;AA6CA;AAAA;AACA;AACA;AACA;AACA;AAEI,YAAC,QAAD;AAAA;AAAA;AAAA;AAAA;AANJ;AAUD;;GApEQhC,Q;;KAAAA,Q;AAsET,eAAeA,QAAf","sourcesContent":["import React, { useState, useEffect, Fragment } from 'react'\r\nimport MicIcon from '@material-ui/icons/Mic';\r\nimport FiberManualRecordIcon from '@material-ui/icons/FiberManualRecord';\r\nimport { Button } from '@material-ui/core';\r\n\r\nimport '../App.css';\r\n\r\nimport axios from 'axios';\r\nimport { DefaultPlayer as Video } from 'react-html5video';\r\nimport 'react-html5video/dist/styles.css';\r\nimport { red } from '@material-ui/core/colors';\r\n\r\nconst SpeechRecognition =\r\nmic.lang = 'th-Th'\r\n  window.SpeechRecognition || window.webkitSpeechRecognition\r\nconst mic = new SpeechRecognition()\r\n\r\nmic.continuous = true\r\nmic.interimResults = true\r\n\r\nfunction VoiceRec() {\r\n  const [isListening, setIsListening] = useState(false)\r\n  const [note, setNote] = useState(null)\r\n  // const [savedNotes, setSavedNotes] = useState([])\r\n  const [cutWordTH, setCutWordTH] = useState([])\r\n \r\n\r\n  var wordList = {};\r\n\r\n  useEffect(() => {\r\n    handleListen();\r\n  }, [isListening])\r\n\r\n  const handleListen = () => {\r\n    if (isListening) {\r\n      mic.start()\r\n      mic.stop()\r\n      mic.onend = () => {\r\n        console.log('continue..')\r\n        mic.start()\r\n      }\r\n    } else {\r\n      mic.onend = () => {\r\n        console.log('Stopped Mic on Click')\r\n      }\r\n    }\r\n    mic.onstart = () => {\r\n      console.log('Mics on')\r\n    }\r\n\r\n    mic.onresult = event => {\r\n      const transcript = Array.from(event.results)\r\n        .map(result => result[0])\r\n        .map(result => result.transcript)\r\n        .join('')\r\n      console.log(transcript)\r\n      setNote(transcript)\r\n\r\n      let config = { 'Apikey': 'rBOeYWQF1L4QEfhffQB7ubqYAJqYSWvQ' };\r\n      //return axios.get(`${apiBaseURL}/v1/cryptocurrency/map`, { headers: config })\r\n\r\n      axios.get(\"https://api.aiforthai.in.th/tlexplus?text=\" + transcript, { headers: config }).then((response) => {\r\n        wordList = response.data.tokens;\r\n        console.log(wordList);\r\n       \r\n        setCutWordTH(wordList);\r\n\r\n      }\r\n      ).catch((error) => {\r\n        // alert(error)\r\n      });\r\n\r\n      mic.onerror = event => {\r\n        console.log(event.error)\r\n      }\r\n    }\r\n  }\r\n\r\n  return (\r\n  // const handleSaveNote = () => {\r\n  //   setSavedNotes([...savedNotes, note])\r\n  //   setNote('')\r\n  // }\r\n\r\n      <Fragment>\r\n      \r\n      </Fragment >\r\n  )\r\n}\r\n\r\nexport default VoiceRec;"]},"metadata":{},"sourceType":"module"}